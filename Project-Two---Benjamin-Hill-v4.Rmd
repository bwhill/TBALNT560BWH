---
title: "Project Two"
author: "Benjamin Hill"
date: "`r format(Sys.time(), '%B, %d, %Y')`"
output:
  pdf_document: 
    toc: yes
    toc_depth: 3
    extra_dependencies: ["float"]
  word_document: default
  html_document: 
    df_print: paged
fig.caption: yes
keep_tex: yes
always_allow_html: true
mainfont: Palatino
header-includes: 
  \usepackage{dcolumn}
  \usepackage{longtable}
  \usepackage{float}
  \usepackage{rotating}
  \floatplacement{figure}{H}
---

\newpage

```{r knitrcode, echo=TRUE, message=FALSE, warning=FALSE}
# This code sets options for when we knit the rmarkdown to a PDF or other doc
knitr::opts_chunk$set(include=TRUE,fig.align='center', comment=NA,fig.pos = '!H')
knitr::opts_knit$set(root.dir = normalizePath("/Users/ben/Documents/UWT/Classes/560 - Data Mining/Project Two Homework/"))
```

```{r instpackage, echo=TRUE, message=FALSE, warning=FALSE}
# keep track of packages that need to be installed in the environment
# install.packages("flextable")
# install.packages("officer")
# install.packages("tibble")
# install.packages("tidyverse")
# install.packages("docxtractr")
# install.packages("compare_df")
# install.packages("DataExplorer")
# install.packages("GPArotation")
# install.packages("psychTools")
# install.packages("PerformanceAnalytics")
# install.packages("hablar")
# install.packages("caretEnsemble")
# install.packages("pivottabler")
# install.packages("rattle")
```

```{r inclibs, echo=TRUE, message=FALSE, warning=FALSE}
# libraries to use - not all are used in the code
library(DataExplorer) 
library(kableExtra)
library(xtable)
library(stargazer)
library(summarytools)
library(e1071)
library(forecast)
library(gplots)
library(ggplot2)
library(rattle)
library(GGally)
library(scales)
library(caret)
library(caretEnsemble)
library(tidyverse)
require(knitr)
library(rpart)
library(rpart.plot)
library(randomForest)
library(adabag)
library(klaR)
library(ipred)

```

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
# default options for this rmarkdown file. 
# I will change these options on a chunk by chunk basis depending on what 
# I am trying to do

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
setwd("/Users/ben/Documents/UWT/Classes/560 - Data Mining/Project Two Homework/")

# clear previous variables and set random seed.
rm(list=ls()) 
set.seed(12345)
```

```{r fsetup, echo=TRUE, message=FALSE, warning=FALSE}
# define any functions used in the code
# the URL references are where I got the code from

# https://stackoverflow.com/questions/2547402/how-to-find-the-statistical-mode
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Max-Min normalization
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# https://stackoverflow.com/questions/31289987/r-xtable-wrap-overflowing-columns-into-subtables

# define a function that takes two parameters:
# - your long data.frame 
# - the number of columns you want to print in one table
varTable <- function( agg, cols, cap ) 
{
  tables <- ceiling( length( agg ) / cols )    # number of tables to produce
  # list, first element is number of sub-tables
  p <- list( tables )
  # produce as many table as needed with the full number of columns
  for( i in 0 : ( tables - 2 ) ) p[[ i + 2 ]] <- xtable( agg[ ( cols * i + 1):( cols * i + cols ) ] )
  # last table may have less columns and takes the caption
  p[[ i + 3 ]] <- xtable( agg[ ( cols * ( i + 1  ) + 1):( length( agg ) ) ], caption = cap )
  # return the list with xtable objects that can now be printed one by one
  return( p )
}

# https://stackoverflow.com/questions/52554336/plot-the-equivalent-of-correlation-matrix-for-factors-categorical-data-and-mi

require(rcompanion)

# Calculate a pairwise association between all variables in a data-frame. In particular nominal vs nominal with Chi-square, numeric vs numeric with Pearson correlation, and nominal vs numeric with ANOVA.
# Adopted from https://stackoverflow.com/a/52557631/590437
mixed_assoc = function(df, cor_method="spearman", adjust_cramersv_bias=TRUE){
    df_comb = expand.grid(names(df), names(df),  stringsAsFactors = F) %>% set_names("X1", "X2")

    is_nominal = function(x) class(x) %in% c("factor", "character")
    # https://community.rstudio.com/t/why-is-purr-is-numeric-deprecated/3559
    # https://github.com/r-lib/rlang/issues/781
    is_numeric <- function(x) { is.integer(x) || is_double(x)}

    f = function(xName,yName) {
        x =  pull(df, xName)
        y =  pull(df, yName)

        result = if(is_nominal(x) && is_nominal(y)){
            # use bias corrected cramersV as described in https://rdrr.io/cran/rcompanion/man/cramerV.html
            cv = cramerV(as.character(x), as.character(y), bias.correct = adjust_cramersv_bias)
            data.frame(xName, yName, assoc=cv, type="cramersV")

        }else if(is_numeric(x) && is_numeric(y)){
            correlation = cor(x, y, method=cor_method, use="complete.obs")
            data.frame(xName, yName, assoc=correlation, type="correlation")
  }else if(is_numeric(x) && is_nominal(y)){
            # from https://stats.stackexchange.com/questions/119835/correlation-between-a-nominal-iv-and-a-continuous-dv-variable/124618#124618
            r_squared = summary(lm(x ~ y))$r.squared
            data.frame(xName, yName, assoc=sqrt(r_squared), type="anova")

        }else if(is_nominal(x) && is_numeric(y)){
            r_squared = summary(lm(y ~x))$r.squared
            data.frame(xName, yName, assoc=sqrt(r_squared), type="anova")

        }else {
            warning(paste("unmatched column type combination: ", class(x), class(y)))
        }

        # finally add complete obs number and ratio to table
        result %>% mutate(complete_obs_pairs=sum(!is.na(x) & !is.na(y)), complete_obs_ratio=complete_obs_pairs/length(x)) %>% rename(x=xName, y=yName)
    }

    # apply function to each variable combination
    map2_df(df_comb$X1, df_comb$X2, f)
}

```

# Data Exploration and Preparation

Developing a Data Mining Portfolio -  End to End Project â€“ Classification

This project involves generating several classification models for the same data set and then combining the output from the models in an ensemble fashion.    An R file is provided that generates classification models using the Iris data set.  You will want to adapt this for the BreastCancer data set which is provided.  You will want to add code that combines the output from the different models using Majority rule ensemble approach. 
## Load And Shape Data

Load the mlbench package which has the BreastCancer data set. Some algorithms don't like missing values, so remove rows with missing values. Remove the unique identifier, which is useless and would confuse the machine learning algorithms.

```{r readdata, echo=TRUE, message=FALSE, warning=FALSE}

#load the mlbench package which has the BreastCancer data set
require(mlbench)

# load the data set
data(BreastCancer)

# some algorithms don't like missing values, so remove rows with missing values
# remove the unique identifier, which is useless and would confuse the machine learning algorithms
# I generally use the tidyverse functions to do any data manipulations

plot_missing(BreastCancer, title="BreastCancer dataset missing values")

df <- BreastCancer %>%
  dplyr::select(-Id) %>%
  drop_na()

# the 'introduce' function is from the DataExplorer package
# https://rdrr.io/cran/DataExplorer/f/vignettes/dataexplorer-intro.Rmd
breastoverview <- as.data.frame(t(introduce(df)))

breastoverview %>%
  dplyr::rename(.,"Overview"="V1") 

print(xtable(breastoverview, 
             caption = "\\tt Breast Cancer Dataset"),
      caption.placement = "top", 
      floating=TRUE, 
      size="\\fontsize{8pt}{10pt}\\selectfont",
      latex.environments = "center", 
      comment=FALSE)

```

# Exploratory Data Analysis

EDA completed on the breast cancer dataset. 

## Data Frame Summary

```{r dfsum, echo=TRUE, message=FALSE, warning=FALSE, results="asis"}
# from the summarytools package
# https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html

dfSummary(df, plain.ascii = FALSE, style = "grid",
          graph.magnif = 0.75, valid.col = FALSE,
          tmp.img.dir = "/tmp")

#ctable(df)

freq(df, plain.ascii = FALSE, 
            headings = TRUE, 
            style = "rmarkdown") 


```

## Missing Data

```{r findmis, echo=TRUE, message=FALSE, warning=FALSE, results="asis"}
# print a table with missing values
# there should be no missing values after I dropped the rows with missing 
# values above
# https://sebastiansauer.github.io/NAs-with-dplyr/

extra_NA <- df %>%
  dplyr::select_if(function(x) any(is.na(x))) %>% 
  dplyr::summarise_each(funs(sum(is.na(.)))) 

x <- profile_missing(df)

add.to.row <- list(pos = list(0), command = NULL)
command <- paste0("\\hline\n\\endhead\n",
"\\hline\n",
"\\multicolumn{", dim(x)[2] + 1, "}{l}", "{\\footnotesize Continued on next page}\n", "\\endfoot\n",
"\\endlastfoot\n")
add.to.row$command <- command

xtable(x) %>% arrange(desc(num_missing)) %>%
  print(., hline.after=c(-1), add.to.row = add.to.row, tabular.environment = "longtable", comment=FALSE)

```

## Cross-Tabulations

```{r ctblsum, echo=TRUE, message=FALSE, warning=FALSE, results="asis"}
# from the summarytools package

# Cross-Tabulations (joint frequencies) between pairs of discrete/categorical variables, featuring marginal sums as well as row, column or total proportions 

ctable(x = df$Cl.thickness, y = df$Class, chisq = TRUE, prop = "r")
ctable(x = df$Cell.size, y = df$Class, chisq = TRUE, prop = "r")
ctable(x = df$Cell.shape, y = df$Class, chisq = TRUE, prop = "r")
ctable(x = df$Marg.adhesion, y = df$Class, chisq = TRUE, prop = "r")
ctable(x = df$Epith.c.size, y = df$Class, chisq = TRUE, prop = "r")
ctable(x = df$Bare.nuclei, y = df$Class, chisq = TRUE, prop = "r")
ctable(x = df$Bl.cromatin, y = df$Class, chisq = TRUE, prop = "r")
ctable(x = df$Normal.nucleoli, y = df$Class, chisq = TRUE, prop = "r")
ctable(x = df$Normal.nucleoli, y = df$Mitoses, chisq = TRUE, prop = "r")

```

### Data Exploration

```{r dxplor, echo=TRUE, message=FALSE, warning=FALSE}
# Using EDA functions from DataExplorer

DataExplorer::plot_bar(df,by="Class",title="BreastCancer dataset",nrow=1L,ncol=2L)

DataExplorer::plot_correlation(df,title="BreastCancer dataset",cor_args = list("use" = "pairwise.complete.obs"))
cat("\n\n\\pagebreak\n")

plot_prcomp(df, 
            maxcat=10L, 
            variance_cap = 0.5,
            parallel=TRUE, 
            nrow = 2L,
            ncol = 1L,
            title = "BreastCancer dataset - Principle Components, Cumululative 50%")


# scatterplot from GGally package
ggpairs(df,         ggplot2::aes(colour=Class)) 
cat("\n\n\\pagebreak\n")



```

```{r dfsplit, echo=TRUE, message=FALSE, warning=FALSE}

# st the percentage of train here it is 0.8
percnt.of.data <- 0.8

# split data
train.index <- createDataPartition(y = df$Class ,
                                   p=percnt.of.data,
                                   list=FALSE)

# We now use the indexes set up to reference the rows we are sampling
train.df <- df[train.index, ]
valid.df <- df[-train.index, ]

```

# Model Development

All models are implemented via caret.

```{r startcore, echo=TRUE, message=FALSE, warning=FALSE}
# I set this on my Mac to use multiple cores - speed up tree models later
library(doParallel)

cl <- makePSOCKcluster(6)

registerDoParallel(cl)

```

\newpage

## Recursive Partitioning and Regression Tree

```{r xdt, echo=TRUE, message=FALSE, warning=FALSE}

ctrl <- trainControl(method = "repeatedcv",
                     number = 10,
                     repeats = 3)

x.rp <- train(Class ~ ., 
              data=train.df,
              method="rpart",
              trControl = ctrl)

#summary(x.rp)
rpart.plot(x.rp$finalModel)

# Make predictions - probabilities
x.rp.prob <- predict(x.rp, type="prob", valid.df)
# score the evaluation data set (extract the probabilities for graphing later)

# convert probabilities into factor for confusion matrix
x.rp.pred <- x.rp.prob %>% 
  as_tibble(.) %>%
  mutate(Class = if_else(benign >= malignant, "benign", "malignant")) %>%
  mutate(Class = as.factor(Class))

# Summarize results
confusionMatrix(x.rp.pred$Class,valid.df$Class)

```

\newpage

## Support Vector Machine

```{r xsvm, echo=TRUE, message=FALSE, warning=FALSE}

# svm requires tuning
xsvm.tune <- tune(svm, Class~., 
                   data = train.df,
                   ranges = list(gamma = 2^(-8:1), 
                                 cost = 2^(0:4)),
                   tunecontrol = tune.control(sampling = "fix"))

# display the tuning results (in text format)
#x.svm.tune

# If the tuning results are on the margin of the parameters (e.g., gamma = 2^-8), then widen the parameters. I manually copied the cost and gamma from console messages above to parameters below.
x.svm <- svm(Class~.,
             data = train.df,
             cost=2, 
             gamma=0.25, 
             probability = TRUE)

x.svm.prob <- predict(x.svm, 
                      type="prob", 
                      newdata=valid.df, 
                      probability = TRUE)

confusionMatrix(x.svm.prob,valid.df$Class)
```

\newpage

## Conditional Inference Tree

```{r xcit, echo=TRUE, message=FALSE, warning=FALSE}

# Leave-1-Out Cross Validation (LOOCV)
fit_control <- trainControl(method="LOOCV")

# create model using conditional inference trees

x.cit <- train(Class ~ ., 
              data=train.df,
              trControl = fit_control,
              method="ctree")
#summary(x.nb)

# predict classes for the evaluation data set
x.cit.pred <- predict(x.cit, valid.df)

confusionMatrix(x.cit.pred,valid.df$Class)

# To view the decision tree, uncomment this line.
plot(x.cit$finalModel, main="Decision tree created using condition inference trees")

# score the evaluation data set (extract the probabilities for graphing later)
x.cit.prob <- predict(x.cit, type="prob", newdata=valid.df)

```

\newpage

## Conditional Inference Random Forest

```{r xrfbecit, echo=TRUE, message=FALSE, warning=FALSE}
# Train model 

x.rfbecit <- train(Class ~ ., 
              data=train.df,
              trControl = fit_control,
              method="cforest")
#summary(x.nb)

# predict classes for the evaluation data set
x.rfbecit.pred <- predict(x.rfbecit, valid.df)

confusionMatrix(x.rfbecit.pred,valid.df$Class)

# score the evaluation data set (extract the probabilities for graphing later)
x.rfbecit.prob <- predict(x.rfbecit, type="prob", newdata=valid.df)

```

\newpage

## Bagged CART

```{r xrfbag, echo=TRUE, message=FALSE, warning=FALSE}

x.xrfbag2 <- train(Class ~ ., 
              data=train.df,
              trControl = fit_control,
              method="treebag")

x.ip.prob2 <- predict(x.xrfbag2, type="prob", newdata=valid.df)

# convert probabilities into factor for confusion matrix
x.ip.prob2 <- x.ip.prob2 %>% 
  as_tibble(.) %>%
  mutate(Class = if_else(benign >= malignant, "benign", "malignant")) %>%
  mutate(Class = as.factor(Class))

confusionMatrix(x.ip.prob2$Class,valid.df$Class)

# score the evaluation data set (extract the probabilities for graphing later)
x.xrfbag2.prob <- predict(x.xrfbag2, type="prob", newdata=valid.df)

```

\newpage

# ROC Curves

```{r commpmodel, echo=TRUE, message=FALSE, warning=FALSE}

##
## plot ROC curves to compare the performance of the individual classifiers
## create an ROCR prediction objects from the various probabilities


# load the ROCR package which draws the ROC curves
require(ROCR)

x.rp.prob.rocr <- prediction(x.rp.prob[,2], valid.df['Class'])
# prepare an ROCR performance object for ROC curve (tpr=true positive rate, fpr=false positive rate)
x.rp.perf <- performance(x.rp.prob.rocr, "tpr","fpr")
# plot it
plot(x.rp.perf, col=2, main="ROC curves comparing classification performance of five machine learning models")

# Draw a legend.
legend(0.6, 0.6, c('rpart', 'svm', 'cit','cforest', 'rforest bagging'), 2:6)

# svm
x.svm.prob.rocr <- prediction(attr(x.svm.prob, "probabilities")[,2], valid.df['Class'])
x.svm.perf <- performance(x.svm.prob.rocr, "tpr","fpr")
plot(x.svm.perf, col=6, add=TRUE)

# ctree
x.cit.prob.rocr <- prediction(x.cit.prob[,2], valid.df['Class'])
x.cit.perf <- performance(x.cit.prob.rocr, "tpr","fpr")
# add=TRUE draws on the existing chart 
plot(x.cit.perf, col=3, add=TRUE)

# cforest
x.rfbecit.prob.rocr <- prediction(x.rfbecit.prob[,2], valid.df['Class'])
x.rfbecit.perf <- performance(x.rfbecit.prob.rocr, "tpr","fpr")
plot(x.rfbecit.perf, col=4, add=TRUE)

# bagging
x.ip.prob2.rocr <- prediction(x.ip.prob2[,2], valid.df['Class'])
x.ip.perf2 <- performance(x.ip.prob2.rocr, "tpr","fpr")
plot(x.ip.perf2, col=5, add=TRUE)


```


# Ensemble

'Manual' code that combines the output from the different models using Majority rule ensemble approach. 


```{r ensemblemodel, echo=TRUE, message=FALSE, warning=FALSE}

# build dataframe with all 
emodel <- cbind(x.svm.prob,
                x.rp.pred$Class,
                x.cit.pred,
                x.rfbecit.pred,
                x.ip.prob2$Class) 

# This uses the Mode function to calculate the mode across the columns
prvalue <- apply(emodel, 1, Mode)

# convert the output into a datafame and create factors
emodel <- as.data.frame(cbind(emodel,prvalue))
emodel$prvalue = as.factor(ifelse(emodel$prvalue == 1, "benign","malignant"))

# create confusion matrix for ensemble model
confusionMatrix(emodel$prvalue,valid.df$Class)

```


```{r buildtable, echo=TRUE, message=FALSE, warning=FALSE}

# build a table comparing all the various model classification accuracy measures

otable <- cbind(confusionMatrix(x.rp.pred$Class,valid.df$Class)[["overall"]],
                confusionMatrix(x.svm.prob,valid.df$Class)[["overall"]],
                confusionMatrix(x.cit.pred,valid.df$Class)[["overall"]],
                confusionMatrix(x.rfbecit.pred,valid.df$Class)[["overall"]],
                confusionMatrix(x.ip.prob2$Class,valid.df$Class)[["overall"]],
                confusionMatrix(emodel$prvalue,valid.df$Class)[["overall"]])

ctable <- cbind(confusionMatrix(x.rp.pred$Class,valid.df$Class)[["byClass"]],
                confusionMatrix(x.svm.prob,valid.df$Class)[["byClass"]],
                confusionMatrix(x.cit.pred,valid.df$Class)[["byClass"]],
                confusionMatrix(x.rfbecit.pred,valid.df$Class)[["byClass"]],
                confusionMatrix(x.ip.prob2$Class,valid.df$Class)[["byClass"]],
                confusionMatrix(x.ip.prob2$Class,valid.df$Class)[["overall"]])

btable <-as.data.frame(rbind(otable,ctable)) %>%
  dplyr::rename("Recursive Partitioning and Regression Tree" = V1,
                "Support Vector Machine" = V2,
                "Conditional Inference Tree" = V3,
                "Conditional Inference Random Forest" = V4,
                "Bagged CART" = V5,
                "Majority Vote Ensemble" = V6)

print(xtable(btable,
       caption="Comparison of classification models with ensemble model",
       digits=c(1,4,4,4,4,4,4)),
      caption.placement = "top", 
      floating=TRUE, 
      size="\\fontsize{8pt}{10pt}\\selectfont",
      latex.environments = "center", 
      comment=FALSE)

# stop parallel cluster
stopCluster(cl)  
```